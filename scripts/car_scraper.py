#!/usr/bin/env python3
"""
CarScraper Pro - Scraping skript pre BazoÅ¡.sk
Tento skript stiahne inzerÃ¡ty, analyzuje ich pomocou AI a uloÅ¾Ã­ do databÃ¡zy
"""

import sys
import os
import requests
from bs4 import BeautifulSoup
import re
import json
import time
import random
from decimal import Decimal

# Pridaj parent adresÃ¡r do path pre import app modulov
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import z hlavnÃ©ho app.py (nie z app package!)
import importlib.util
app_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'app.py')
spec = importlib.util.spec_from_file_location("main_app", app_path)
main_app = importlib.util.module_from_spec(spec)
spec.loader.exec_module(main_app)
app = main_app.app
db = main_app.db
Project = main_app.Project
CarDeal = main_app.CarDeal

# Import proxy manager
try:
    from utils.proxy_manager import safe_request
    PROXY_AVAILABLE = True
except ImportError:
    PROXY_AVAILABLE = False
    import logging
    logging.warning('Proxy manager nie je dostupnÃ½, pouÅ¾Ã­vam priame requesty')

def safe_extract_price(text):
    """BezpeÄne vytiahne cenu z textu"""
    if isinstance(text, (int, float)):
        return int(text)
    if isinstance(text, Decimal):
        return int(text)
    # NÃ¡jde prvÃ© ÄÃ­slo v texte
    numbers = re.findall(r'\d+', str(text).replace(' ', '').replace(',', ''))
    if numbers:
        return int(numbers[0])
    return 0

def scrape_bazos(search_query="octavia", min_price=1000, max_price=30000):
    """
    Scrapuje inzerÃ¡ty - pouÅ¾Ã­va unified scraper s viacerÃ½mi zdrojmi
    Automaticky pouÅ¾Ã­va fallback ak unified scraper nie je dostupnÃ½
    """
    try:
        from scripts.car_scraper_unified import scrape_all_sources
        results = scrape_all_sources(search_query, min_price, max_price, mode="parallel")
        # VrÃ¡Å¥ zoznam inzerÃ¡tov (nie dict)
        if isinstance(results, dict):
            return results.get('listings', [])
        return results if isinstance(results, list) else []
    except ImportError as e:
        print(f"âš ï¸ Unified scraper nie je dostupnÃ½, pouÅ¾Ã­vam fallback: {e}")
        return scrape_bazos_fallback(search_query, min_price, max_price)
    except Exception as e:
        print(f"âš ï¸ Chyba v unified scraper, pouÅ¾Ã­vam fallback: {e}")
        return scrape_bazos_fallback(search_query, min_price, max_price)

def scrape_bazos_fallback(search_query="octavia", min_price=1000, max_price=30000):
    """Scrapuje inzerÃ¡ty z BazoÅ¡.sk s proxy rotÃ¡ciou a ochranou proti blokovaniu"""
    url = f"https://auto.bazos.sk/skoda/?hledat={search_query}&rubriky=auto&hlokalita=&humkreis=25&cenaod={min_price}&cenado={max_price}&order=1"
    
    print(f"ğŸ”„ SÅ¥ahujem inzerÃ¡ty z: {url}")
    
    # PouÅ¾i safe_request s proxy ak je dostupnÃ©
    if PROXY_AVAILABLE:
        response = safe_request(url, max_retries=3, delay=2.0)
        if not response:
            print("âŒ Chyba pri sÅ¥ahovanÃ­ (vÅ¡etky proxy zlyhali)")
            return []
    else:
        # Fallback na priamy request
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        try:
            # NÃ¡hodnÃ½ delay pre simulÃ¡ciu Ä¾udskÃ©ho sprÃ¡vania
            time.sleep(random.uniform(0.5, 1.0))
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
        except Exception as e:
            print(f"âŒ Chyba pri sÅ¥ahovanÃ­: {e}")
            return []
    
    if not response:
        return []
    
    # Skontroluj, Äi sme dostali validnÃ½ HTML (nie blokovacÃ­ page)
    response_text = response.text.lower() if hasattr(response, 'text') else ''
    if 'blocked' in response_text or 'access denied' in response_text:
        print("âš ï¸ Pravdepodobne blokovanÃ½ - rotujem proxy...")
        # Proxy sa nedÃ¡ zÃ­skaÅ¥ priamo z response, pouÅ¾ije sa pri ÄalÅ¡om requeste
        return []
    
    soup = BeautifulSoup(response.text, 'html.parser')
    listings = []
    
    items = soup.select("div.inzeraty")
    print(f"ğŸ” NaÅ¡iel som {len(items)} inzerÃ¡tov")
    
    for item in items:
        try:
            title_tag = item.select_one("h2.nadpis a")
            if not title_tag:
                continue
            
            title = title_tag.text.strip()
            href = title_tag.get('href', '')
            # Zajisti, Å¾e href je string
            if isinstance(href, list):
                href = href[0] if href else ''
            elif not isinstance(href, str):
                href = str(href) if href else ''
            link = "https://auto.bazos.sk" + href
            
            desc_tag = item.select_one("div.popis")
            description = desc_tag.text.strip() if desc_tag else "Bez popisu"
            
            price_tag = item.select_one("div.inzeratycena b")
            price_text = price_tag.text.strip() if price_tag else "0"
            price = safe_extract_price(price_text)
            
            if price > 500:
                listings.append({
                    "title": title,
                    "price": price,
                    "description": description,
                    "link": link,
                    "source": "BazoÅ¡.sk"
                })
        except Exception as e:
            print(f"âš ï¸ Chyba pri parsovanÃ­ inzerÃ¡tu: {e}")
            continue
    
    return listings[:10]  # VrÃ¡Å¥ prvÃ½ch 10 pre testovanie

def analyze_with_ai(car_data, openai_client=None):
    """Analyzuje auto pomocou AI (ak je OpenAI dostupnÃ©)"""
    if not openai_client:
        # Fallback analÃ½za bez AI
        market_value = int(car_data['price'] * 1.15)  # Odhad +15%
        profit = market_value - car_data['price']
        
        if profit > 2000:
            verdict = "KÃšPIÅ¤"
            risk_level = "NÃ­zke"
            reason = "VÃ½razne pod trhovou cenou"
        elif profit > 500:
            verdict = "RIZIKO"
            risk_level = "StrednÃ©"
            reason = "Mierne pod trhovou cenou"
        else:
            verdict = "NEKUPOVAÅ¤"
            risk_level = "NÃ­zke"
            reason = "Cena je v norme alebo nad trhovou"
        
        return {
            "odhad_ceny_cislo": market_value,
            "verdikt": verdict,
            "risk_level": risk_level,
            "dovod_skratene": reason
        }
    
    # TODO: ImplementovaÅ¥ OpenAI analÃ½zu ak je dostupnÃ¡
    # PouÅ¾i podobnÃº logiku ako v Colab template
    return {
        "odhad_ceny_cislo": int(car_data['price'] * 1.15),
        "verdikt": "RIZIKO",
        "risk_level": "StrednÃ©",
        "dovod_skratene": "AI analÃ½za nie je implementovanÃ¡"
    }

def save_deals_to_db(listings, project_id):
    """UloÅ¾Ã­ deals do databÃ¡zy"""
    saved_count = 0
    
    with app.app_context():
        for listing in listings:
            try:
                # Skontroluj, Äi uÅ¾ existuje (podÄ¾a linku)
                existing = CarDeal.query.filter_by(link=listing['link']).first()
                if existing:
                    continue
                
                # AI analÃ½za
                analysis = analyze_with_ai(listing)
                
                market_value = analysis.get('odhad_ceny_cislo', listing['price'])
                profit = market_value - listing['price']
                
                # type: ignore[call-arg]
                deal = CarDeal(
                    project_id=project_id,  # type: ignore[arg-type]
                    title=listing['title'],  # type: ignore[arg-type]
                    price=Decimal(str(listing['price'])),  # type: ignore[arg-type]
                    market_value=Decimal(str(market_value)),  # type: ignore[arg-type]
                    profit=Decimal(str(profit)),  # type: ignore[arg-type]
                    verdict=analysis.get('verdikt', 'RIZIKO'),  # type: ignore[arg-type]
                    risk_level=analysis.get('risk_level', 'StrednÃ©'),  # type: ignore[arg-type]
                    reason=analysis.get('dovod_skratene', ''),  # type: ignore[arg-type]
                    source=listing.get('source', 'BazoÅ¡.sk'),  # type: ignore[arg-type]
                    link=listing['link'],  # type: ignore[arg-type]
                    description=listing.get('description', ''),  # type: ignore[arg-type]
                    image_url=listing.get('image_url', ''),  # type: ignore[arg-type]
                    ai_analysis=json.dumps(analysis),  # type: ignore[arg-type]
                    brand=listing.get('brand'),
                    model=listing.get('model'),
                    generation=listing.get('generation'),
                    region=listing.get('region'),
                    fuel_type=listing.get('fuel_type'),
                    transmission=listing.get('transmission')
                )
                
                db.session.add(deal)
                saved_count += 1
            except Exception as e:
                print(f"âš ï¸ Chyba pri ukladanÃ­ deal: {e}")
                continue
        
        db.session.commit()
        print(f"âœ… UloÅ¾enÃ½ch {saved_count} novÃ½ch deals")
    
    return saved_count

POPULAR_BRANDS = [
    'Skoda', 'Volkswagen', 'Audi', 'BMW', 'Mercedes-Benz', 
    'Hyundai', 'Kia', 'Toyota', 'Peugeot', 'Renault', 
    'Ford', 'Opel', 'Dacia', 'Fiat', 'Seat'
]

def main(user_id=None, brand=None):
    """HlavnÃ¡ funkcia
    
    Args:
        user_id: ID pouÅ¾Ã­vateÄ¾a pre ktorÃ©ho sa mÃ¡ vytvoriÅ¥/nÃ¡jsÅ¥ projekt.
        brand: KonkrÃ©tna znaÄka na vyhÄ¾adÃ¡vanie. Ak je None, prejde vÅ¡etky top znaÄky (onboarding).
    """
    print(f"ğŸš— CarScraper Pro - SpÃºÅ¡Å¥am {'onboarding' if not brand else 'scraping pre ' + brand}...")
    
    with app.app_context():
        # NÃ¡jdeme alebo vytvorÃ­me CarScraper Pro projekt
        if user_id:
            project = Project.query.filter_by(name='CarScraper Pro', user_id=user_id).first()
        else:
            project = Project.query.filter_by(name='CarScraper Pro').first()
        
        if not project:
            User = main_app.User
            target_user = User.query.get(user_id) if user_id else User.query.filter_by(username='admin').first()
            
            if not target_user:
                print("âŒ PouÅ¾Ã­vateÄ¾ neexistuje!")
                return
            
            # type: ignore[call-arg]
            project = Project(
                name='CarScraper Pro',
                api_key=os.urandom(24).hex(),
                is_active=True,
                user_id=target_user.id
            )
            db.session.add(project)
            db.session.commit()
            print(f"âœ… VytvorenÃ½ projekt CarScraper Pro (ID: {project.id})")

        # Rozhodovanie o znaÄkÃ¡ch
        brands_to_process = [brand] if brand else POPULAR_BRANDS
        total_saved = 0
        
        for b in brands_to_process:
            print(f"ğŸ” SpracovÃ¡vam znaÄku: {b}...")
            # Scraping (limitujeme interne v scraperoch alebo manuÃ¡lne)
            # scrape_bazos pouÅ¾Ã­va unified, ktorÃ½ by mal reÅ¡pektovaÅ¥ dotaz
            listings = scrape_bazos(search_query=b.lower())
            
            if listings:
                # UloÅ¾Ã­me max 10 pre tÃºto znaÄku (ak je to onboarding)
                to_save = listings[:10] if not brand else listings
                saved = save_deals_to_db(to_save, project.id)
                total_saved += saved
                print(f"âœ… [{b}] NÃ¡jdenÃ½ch {len(listings)}, uloÅ¾enÃ½ch {saved} novÃ½ch")
            else:
                print(f"âš ï¸ [{b}] Å½iadne vÃ½sledky")
            
            # Pauza medzi znaÄkami aby sme neboli zablokovanÃ­
            if len(brands_to_process) > 1:
                time.sleep(1)

        print(f"âœ… Hotovo! Celkom uloÅ¾enÃ½ch {total_saved} novÃ½ch inzerÃ¡tov")

if __name__ == '__main__':
    # Ak je zadanÃ½ argument, pouÅ¾i ho ako znaÄku
    target_brand = sys.argv[1] if len(sys.argv) > 1 else None
    main(brand=target_brand)

