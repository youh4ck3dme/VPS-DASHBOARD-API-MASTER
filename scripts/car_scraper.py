#!/usr/bin/env python3
"""
CarScraper Pro - Scraping skript pre Bazo≈°.sk
Tento skript stiahne inzer√°ty, analyzuje ich pomocou AI a ulo≈æ√≠ do datab√°zy
"""

import sys
import os
import requests
from bs4 import BeautifulSoup
import re
import json
import time
import random
from decimal import Decimal

# Pridaj parent adres√°r do path pre import app modulov
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import app, db, Project, CarDeal

# Import proxy manager
try:
    from utils.proxy_manager import safe_request
    PROXY_AVAILABLE = True
except ImportError:
    PROXY_AVAILABLE = False
    import logging
    logging.warning('Proxy manager nie je dostupn√Ω, pou≈æ√≠vam priame requesty')

def safe_extract_price(text):
    """Bezpeƒçne vytiahne cenu z textu"""
    if isinstance(text, (int, float)):
        return int(text)
    if isinstance(text, Decimal):
        return int(text)
    # N√°jde prv√© ƒç√≠slo v texte
    numbers = re.findall(r'\d+', str(text).replace(' ', '').replace(',', ''))
    if numbers:
        return int(numbers[0])
    return 0

def scrape_bazos(search_query="octavia", min_price=1000, max_price=30000):
    """
    Scrapuje inzer√°ty - pou≈æ√≠va unified scraper s viacer√Ωmi zdrojmi
    Automaticky pou≈æ√≠va fallback ak unified scraper nie je dostupn√Ω
    """
    try:
        from scripts.car_scraper_unified import scrape_all_sources
        results = scrape_all_sources(search_query, min_price, max_price, mode="parallel")
        # Vr√°≈• zoznam inzer√°tov (nie dict)
        if isinstance(results, dict):
            return results.get('listings', [])
        return results if isinstance(results, list) else []
    except ImportError as e:
        print(f"‚ö†Ô∏è Unified scraper nie je dostupn√Ω, pou≈æ√≠vam fallback: {e}")
        return scrape_bazos_fallback(search_query, min_price, max_price)
    except Exception as e:
        print(f"‚ö†Ô∏è Chyba v unified scraper, pou≈æ√≠vam fallback: {e}")
        return scrape_bazos_fallback(search_query, min_price, max_price)

def scrape_bazos_fallback(search_query="octavia", min_price=1000, max_price=30000):
    """Scrapuje inzer√°ty z Bazo≈°.sk s proxy rot√°ciou a ochranou proti blokovaniu"""
    url = f"https://auto.bazos.sk/skoda/?hledat={search_query}&rubriky=auto&hlokalita=&humkreis=25&cenaod={min_price}&cenado={max_price}&order=1"
    
    print(f"üîÑ S≈•ahujem inzer√°ty z: {url}")
    
    # Pou≈æi safe_request s proxy ak je dostupn√©
    if PROXY_AVAILABLE:
        response = safe_request(url, max_retries=3, delay=2.0)
        if not response:
            print("‚ùå Chyba pri s≈•ahovan√≠ (v≈°etky proxy zlyhali)")
            return []
    else:
        # Fallback na priamy request
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        try:
            # N√°hodn√Ω delay pre simul√°ciu ƒæudsk√©ho spr√°vania
            time.sleep(random.uniform(1.0, 3.0))
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
        except Exception as e:
            print(f"‚ùå Chyba pri s≈•ahovan√≠: {e}")
            return []
    
    if not response:
        return []
    
    # Skontroluj, ƒçi sme dostali validn√Ω HTML (nie blokovac√≠ page)
    response_text = response.text.lower() if hasattr(response, 'text') else ''
    if 'blocked' in response_text or 'access denied' in response_text:
        print("‚ö†Ô∏è Pravdepodobne blokovan√Ω - rotujem proxy...")
        # Proxy sa ned√° z√≠ska≈• priamo z response, pou≈æije sa pri ƒèal≈°om requeste
        return []
    
    soup = BeautifulSoup(response.text, 'html.parser')
    listings = []
    
    items = soup.select("div.inzeraty")
    print(f"üîé Na≈°iel som {len(items)} inzer√°tov")
    
    for item in items:
        try:
            title_tag = item.select_one("h2.nadpis a")
            if not title_tag:
                continue
            
            title = title_tag.text.strip()
            href = title_tag.get('href', '')
            # Zajisti, ≈æe href je string
            if isinstance(href, list):
                href = href[0] if href else ''
            elif not isinstance(href, str):
                href = str(href) if href else ''
            link = "https://auto.bazos.sk" + href
            
            desc_tag = item.select_one("div.popis")
            description = desc_tag.text.strip() if desc_tag else "Bez popisu"
            
            price_tag = item.select_one("div.inzeratycena b")
            price_text = price_tag.text.strip() if price_tag else "0"
            price = safe_extract_price(price_text)
            
            if price > 500:
                listings.append({
                    "title": title,
                    "price": price,
                    "description": description,
                    "link": link,
                    "source": "Bazo≈°.sk"
                })
        except Exception as e:
            print(f"‚ö†Ô∏è Chyba pri parsovan√≠ inzer√°tu: {e}")
            continue
    
    return listings[:10]  # Vr√°≈• prv√Ωch 10 pre testovanie

def analyze_with_ai(car_data, openai_client=None):
    """Analyzuje auto pomocou AI (ak je OpenAI dostupn√©)"""
    if not openai_client:
        # Fallback anal√Ωza bez AI
        market_value = int(car_data['price'] * 1.15)  # Odhad +15%
        profit = market_value - car_data['price']
        
        if profit > 2000:
            verdict = "K√öPI≈§"
            risk_level = "N√≠zke"
            reason = "V√Ωrazne pod trhovou cenou"
        elif profit > 500:
            verdict = "RIZIKO"
            risk_level = "Stredn√©"
            reason = "Mierne pod trhovou cenou"
        else:
            verdict = "NEKUPOVA≈§"
            risk_level = "N√≠zke"
            reason = "Cena je v norme alebo nad trhovou"
        
        return {
            "odhad_ceny_cislo": market_value,
            "verdikt": verdict,
            "risk_level": risk_level,
            "dovod_skratene": reason
        }
    
    # TODO: Implementova≈• OpenAI anal√Ωzu ak je dostupn√°
    # Pou≈æi podobn√∫ logiku ako v Colab template
    return {
        "odhad_ceny_cislo": int(car_data['price'] * 1.15),
        "verdikt": "RIZIKO",
        "risk_level": "Stredn√©",
        "dovod_skratene": "AI anal√Ωza nie je implementovan√°"
    }

def save_deals_to_db(listings, project_id):
    """Ulo≈æ√≠ deals do datab√°zy"""
    saved_count = 0
    
    with app.app_context():
        for listing in listings:
            try:
                # Skontroluj, ƒçi u≈æ existuje (podƒæa linku)
                existing = CarDeal.query.filter_by(link=listing['link']).first()
                if existing:
                    continue
                
                # AI anal√Ωza
                analysis = analyze_with_ai(listing)
                
                market_value = analysis.get('odhad_ceny_cislo', listing['price'])
                profit = market_value - listing['price']
                
                # type: ignore[call-arg]
                deal = CarDeal(
                    project_id=project_id,  # type: ignore[arg-type]
                    title=listing['title'],  # type: ignore[arg-type]
                    price=Decimal(str(listing['price'])),  # type: ignore[arg-type]
                    market_value=Decimal(str(market_value)),  # type: ignore[arg-type]
                    profit=Decimal(str(profit)),  # type: ignore[arg-type]
                    verdict=analysis.get('verdikt', 'RIZIKO'),  # type: ignore[arg-type]
                    risk_level=analysis.get('risk_level', 'Stredn√©'),  # type: ignore[arg-type]
                    reason=analysis.get('dovod_skratene', ''),  # type: ignore[arg-type]
                    source=listing.get('source', 'Bazo≈°.sk'),  # type: ignore[arg-type]
                    link=listing['link'],  # type: ignore[arg-type]
                    description=listing.get('description', ''),  # type: ignore[arg-type]
                    image_url=listing.get('image_url', ''),  # type: ignore[arg-type]
                    ai_analysis=json.dumps(analysis)  # type: ignore[arg-type]
                )
                
                db.session.add(deal)
                saved_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Chyba pri ukladan√≠ deal: {e}")
                continue
        
        db.session.commit()
        print(f"‚úÖ Ulo≈æen√Ωch {saved_count} nov√Ωch deals")
    
    return saved_count

def main(user_id=None):
    """Hlavn√° funkcia
    
    Args:
        user_id: ID pou≈æ√≠vateƒæa pre ktor√©ho sa m√° vytvori≈•/n√°js≈• projekt.
                 Ak nie je zadan√Ω, pou≈æije sa admin pou≈æ√≠vateƒæ.
    """
    print("üöó CarScraper Pro - Sp√∫≈°≈•am scraping...")
    
    with app.app_context():
        # N√°jdeme alebo vytvor√≠me CarScraper Pro projekt
        if user_id:
            # Hƒæad√°me projekt pre konkr√©tneho pou≈æ√≠vateƒæa
            project = Project.query.filter_by(name='CarScraper Pro', user_id=user_id).first()
        else:
            # Fallback na admin pou≈æ√≠vateƒæa (pre kompatibilitu)
            project = Project.query.filter_by(name='CarScraper Pro').first()
        
        if not project:
            # Vytvor√≠me projekt
            from app import User
            if user_id:
                target_user = User.query.get(user_id)
            else:
                target_user = User.query.filter_by(username='admin').first()
            
            if not target_user:
                print("‚ùå Pou≈æ√≠vateƒæ neexistuje!")
                return
            
            # type: ignore[call-arg]
            project = Project(
                name='CarScraper Pro',  # type: ignore[arg-type]
                api_key=os.urandom(24).hex(),  # type: ignore[arg-type]
                is_active=True,  # type: ignore[arg-type]
                user_id=target_user.id  # type: ignore[arg-type]
            )
            db.session.add(project)
            db.session.commit()
            print(f"‚úÖ Vytvoren√Ω projekt CarScraper Pro (ID: {project.id}) pre pou≈æ√≠vateƒæa {target_user.username}")
        
        # Scraping
        listings = scrape_bazos()
        
        if not listings:
            print("‚ùå ≈Ωiadne inzer√°ty na spracovanie")
            return
        
        # Ulo≈æenie do DB
        saved = save_deals_to_db(listings, project.id)
        
        print(f"‚úÖ Hotovo! Spracovan√Ωch {len(listings)} inzer√°tov, ulo≈æen√Ωch {saved} nov√Ωch")

if __name__ == '__main__':
    main()

